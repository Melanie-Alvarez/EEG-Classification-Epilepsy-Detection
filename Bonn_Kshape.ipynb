{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OlXdBOfIVaxU",
        "outputId": "a83d6a51-b0b3-4d07-bb22-c594064de795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando validación cruzada sobre el grid de parámetros...\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-08}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-08} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-08}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 3, 'tol': 1e-08} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-08}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 5, 'tol': 1e-08} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-08}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 7, 'tol': 1e-08} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-08}\n",
            "Configuración: {'metric': 'euclidean', 'n_clusters': 2, 'n_init': 10, 'tol': 1e-08} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 0.0001}\n",
            "Configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 0.0001} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-05}\n",
            "Configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-05} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-06}\n",
            "Configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-06} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-07}\n",
            "Configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-07} -> CV Accuracy: 0.7750\n",
            "\n",
            "Probando configuración: {'metric': 'dtw', 'n_clusters': 2, 'n_init': 1, 'tol': 1e-08}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1b1c162a8b41>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                        \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                        random_state=0)\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cv_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Predecir en el fold de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tslearn/clustering/kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Init %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_successful\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                 \u001b[0mn_attempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_one_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                     \u001b[0mbest_correct_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tslearn/clustering/kmeans.py\u001b[0m in \u001b[0;36m_fit_one_init\u001b[0;34m(self, X, x_squared_norms, rs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" --> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_inertia\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tslearn/clustering/kmeans.py\u001b[0m in \u001b[0;36m_update_centroids\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dtw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                 self.cluster_centers_[k] = dtw_barycenter_averaging(\n\u001b[0m\u001b[1;32m    748\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mbarycenter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tslearn/barycenters/dba.py\u001b[0m in \u001b[0;36mdtw_barycenter_averaging\u001b[0;34m(X, barycenter_size, init_barycenter, max_iter, tol, weights, metric_params, verbose, n_init)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attempt {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         bary, loss = dtw_barycenter_averaging_one_init(\n\u001b[0m\u001b[1;32m    499\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mbarycenter_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbarycenter_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tslearn/barycenters/dba.py\u001b[0m in \u001b[0;36mdtw_barycenter_averaging_one_init\u001b[0;34m(X, barycenter_size, init_barycenter, max_iter, tol, weights, metric_params, verbose)\u001b[0m\n\u001b[1;32m    591\u001b[0m         diag_sum_v_k, list_w_k = _mm_valence_warping(list_p_k, barycenter_size,\n\u001b[1;32m    592\u001b[0m                                                      weights)\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[DBA] epoch %d, cost: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mbarycenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mm_update_barycenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag_sum_v_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_w_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tslearn.clustering import KShape, TimeSeriesKMeans\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
        "from tslearn.utils import to_time_series_dataset\n",
        "from sklearn.model_selection import train_test_split, KFold, ParameterGrid\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Cargar datos\n",
        "data = np.loadtxt(\"/mnt/DGX0Raid/databases/bonn_dataset_columns_correct.csv\", delimiter=\",\")[:, :].T\n",
        "dataDF = pd.DataFrame(data)\n",
        "X = to_time_series_dataset(data[:, 1:])\n",
        "y = data[:, 0]\n",
        "\n",
        "# Función para extraer los primeros 21 segundos de cada señal EEG y usar yield\n",
        "def extract_21_seconds_generator(X, fs=173.61, window_duration=8):\n",
        "    \"\"\"\n",
        "    Generador para extraer los primeros 'window_duration' segundos de cada señal EEG.\n",
        "    'fs' es la frecuencia de muestreo (samples per second).\n",
        "    \"\"\"\n",
        "    # Convertir los segundos a número de muestras\n",
        "    num_samples = int(window_duration * fs)\n",
        "\n",
        "    # Iterar sobre las señales y extraer la parte correspondiente\n",
        "    for signal in X:\n",
        "        yield signal[:num_samples]\n",
        "\n",
        "# Crear un generador para los segmentos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Usar el generador para obtener los primeros 21 segundos de cada señal\n",
        "X_train_extracted = np.array(list(extract_21_seconds_generator(X_train)))\n",
        "X_test_extracted = np.array(list(extract_21_seconds_generator(X_test)))\n",
        "\n",
        "# Eliminar la última dimensión\n",
        "X_train_extracted = X_train_extracted.squeeze(-1)\n",
        "X_test_extracted = X_test_extracted.squeeze(-1)\n",
        "\n",
        "# Función de filtro pasa bajos\n",
        "def low_pass_filter(signal, cutoff=40.0, fs=173.61, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "# Parámetros del filtro\n",
        "cutoff_freq = 40.0\n",
        "fs = 173.61\n",
        "\n",
        "# Filtrar las señales EEG\n",
        "X_train_filtered = np.array([low_pass_filter(signal, cutoff=cutoff_freq, fs=fs) for signal in X_train_extracted])\n",
        "X_test_filtered = np.array([low_pass_filter(signal, cutoff=cutoff_freq, fs=fs) for signal in X_test_extracted])\n",
        "\n",
        "# Usar únicamente TimeSeriesScalerMeanVariance\n",
        "scaler = TimeSeriesScalerMeanVariance(mu=0., std=1.)\n",
        "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
        "X_test_scaled = scaler.transform(X_test_filtered)\n",
        "\n",
        "# Función para mapear clusters a etiquetas reales\n",
        "def map_clusters_to_labels(clusters, true_labels):\n",
        "    true_labels = np.array(true_labels, dtype=int)\n",
        "    label_map = {}\n",
        "    for cluster in np.unique(clusters):\n",
        "        mask = (clusters == cluster)\n",
        "        true_mode = mode(true_labels[mask], keepdims=True).mode[0]\n",
        "        label_map[cluster] = true_mode\n",
        "    return np.array([label_map[c] for c in clusters]), label_map\n",
        "\n",
        "# 3) Define la malla de hiperparámetros\n",
        "param_grid = {\n",
        "    \"n_clusters\": [2],\n",
        "    \"metric\": [\"euclidean\", \"dtw\"],\n",
        "    \"n_init\": [1, 3, 5, 7, 10],\n",
        "    \"tol\": [1e-4, 1e-5, 1e-6, 1e-7, 1e-8]\n",
        "}\n",
        "\n",
        "# Validación cruzada KFold con 10 folds en el conjunto de entrenamiento\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_cv_score = -np.inf\n",
        "best_params = None\n",
        "\n",
        "print(\"Iniciando validación cruzada sobre el grid de parámetros...\")\n",
        "for params in ParameterGrid(param_grid):\n",
        "    cv_scores = []\n",
        "    print(f\"\\nProbando configuración: {params}\")\n",
        "    for train_index, val_index in kf.split(X_train_scaled):\n",
        "        X_cv_train = X_train_scaled[train_index]\n",
        "        X_cv_val = X_train_scaled[val_index]\n",
        "        y_cv_train = y_train[train_index]\n",
        "        y_cv_val = y_train[val_index]\n",
        "\n",
        "        # Entrenar el modelo KShape con la configuración actual\n",
        "        model = TimeSeriesKMeans(n_clusters=params['n_clusters'],\n",
        "                       metric=params['metric'],\n",
        "                       n_init=params['n_init'],\n",
        "                       tol=params['tol'],\n",
        "                       random_state=0)\n",
        "        model.fit(X_cv_train)\n",
        "\n",
        "        # Predecir en el fold de validación\n",
        "        y_pred_val = model.predict(X_cv_val)\n",
        "        mapped_val, _ = map_clusters_to_labels(y_pred_val, y_cv_val)\n",
        "        cv_acc = accuracy_score(y_cv_val, mapped_val)\n",
        "        cv_scores.append(cv_acc)\n",
        "\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "    print(f\"Configuración: {params} -> CV Accuracy: {mean_cv_score:.4f}\")\n",
        "    if mean_cv_score > best_cv_score:\n",
        "        best_cv_score = mean_cv_score\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\n====== Mejor configuración (CV) ======\")\n",
        "print(\"Mejor configuración:\", best_params)\n",
        "print(\"Mejor CV Accuracy:\", best_cv_score)\n",
        "\n",
        "# Reentrenar el modelo con la mejor configuración en todo el conjunto de entrenamiento\n",
        "best_model = KShape(n_clusters=best_params['n_clusters'],\n",
        "                    n_init=best_params['n_init'],\n",
        "                    tol=best_params['tol'],\n",
        "                    random_state=0)\n",
        "best_model.fit(X_train_scaled)\n",
        "\n",
        "# Evaluar en el conjunto de entrenamiento\n",
        "y_pred_train = best_model.predict(X_train_scaled)\n",
        "mapped_train, _ = map_clusters_to_labels(y_pred_train, y_train)\n",
        "train_acc = accuracy_score(y_train, mapped_train)\n",
        "print(\"\\n====== Evaluación en el conjunto de entrenamiento ======\")\n",
        "print(\"Train Accuracy:\", train_acc)\n",
        "print(\"\\nReporte de clasificación (Entrenamiento):\")\n",
        "print(classification_report(y_train, mapped_train))\n",
        "cm_train = confusion_matrix(y_train, mapped_train)\n",
        "print(\"\\nMatriz de confusión (Entrenamiento):\")\n",
        "print(cm_train)\n",
        "\n",
        "# Evaluar en el conjunto de prueba\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "mapped_test, _ = map_clusters_to_labels(y_pred_test, y_test)\n",
        "test_acc = accuracy_score(y_test, mapped_test)\n",
        "print(\"\\n====== Evaluación en el conjunto de prueba ======\")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"\\nReporte de clasificación (Prueba):\")\n",
        "print(classification_report(y_test, mapped_test))\n",
        "cm_test = confusion_matrix(y_test, mapped_test)\n",
        "print(\"\\nMatriz de confusión (Prueba):\")\n",
        "print(cm_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tslearn.clustering import KShape\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
        "from tslearn.utils import to_time_series_dataset\n",
        "from sklearn.model_selection import train_test_split, KFold, ParameterGrid\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Cargar datos\n",
        "data = np.loadtxt(\"/mnt/DGX0Raid/databases/bonn_dataset_columns_correct.csv\", delimiter=\",\")[:, :].T\n",
        "dataDF = pd.DataFrame(data)\n",
        "X = to_time_series_dataset(data[:, 1:])\n",
        "y = data[:, 0]\n",
        "\n",
        "# Función para extraer los primeros 21 segundos de cada señal EEG y usar yield\n",
        "def extract_21_seconds_generator(X, fs=173.61, window_duration=5):\n",
        "    \"\"\"\n",
        "    Generador para extraer los primeros 'window_duration' segundos de cada señal EEG.\n",
        "    'fs' es la frecuencia de muestreo (samples per second).\n",
        "    \"\"\"\n",
        "    # Convertir los segundos a número de muestras\n",
        "    num_samples = int(window_duration * fs)\n",
        "\n",
        "    # Iterar sobre las señales y extraer la parte correspondiente\n",
        "    for signal in X:\n",
        "        yield signal[:num_samples]\n",
        "\n",
        "# Crear un generador para los segmentos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Usar el generador para obtener los primeros 21 segundos de cada señal\n",
        "X_train_extracted = np.array(list(extract_21_seconds_generator(X_train)))\n",
        "X_test_extracted = np.array(list(extract_21_seconds_generator(X_test)))\n",
        "\n",
        "# Eliminar la última dimensión\n",
        "X_train_extracted = X_train_extracted.squeeze(-1)\n",
        "X_test_extracted = X_test_extracted.squeeze(-1)\n",
        "\n",
        "# Usar únicamente TimeSeriesScalerMeanVariance\n",
        "scaler = TimeSeriesScalerMeanVariance(mu=0., std=1.)\n",
        "\n",
        "# Seleccionar la señal filtrada con el orden deseado (por ejemplo, orden 2)\n",
        "X_train_scaled = scaler.fit_transform(X_train_extracted)\n",
        "X_test_scaled = scaler.transform(X_test_extracted)\n",
        "\n",
        "# Función para mapear clusters a etiquetas reales\n",
        "def map_clusters_to_labels(clusters, true_labels):\n",
        "    true_labels = np.array(true_labels, dtype=int)\n",
        "    label_map = {}\n",
        "    for cluster in np.unique(clusters):\n",
        "        mask = (clusters == cluster)\n",
        "        true_mode = mode(true_labels[mask], keepdims=True).mode[0]\n",
        "        label_map[cluster] = true_mode\n",
        "    return np.array([label_map[c] for c in clusters]), label_map\n",
        "\n",
        "# Definir el grid de hiperparámetros a probar\n",
        "param_grid = {\n",
        "    'n_clusters': [2],\n",
        "    'n_init': [1, 3, 5, 7, 10],\n",
        "    'tol': [1e-4, 1e-5, 1e-6, 1e-7, 1e-8]\n",
        "}\n",
        "\n",
        "# Validación cruzada KFold con 10 folds en el conjunto de entrenamiento\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_cv_score = -np.inf\n",
        "best_params = None\n",
        "\n",
        "print(\"Iniciando validación cruzada sobre el grid de parámetros...\")\n",
        "for params in ParameterGrid(param_grid):\n",
        "    cv_scores = []\n",
        "    print(f\"\\nProbando configuración: {params}\")\n",
        "    for train_index, val_index in kf.split(X_train_scaled):\n",
        "        X_cv_train = X_train_scaled[train_index]\n",
        "        X_cv_val = X_train_scaled[val_index]\n",
        "        y_cv_train = y_train[train_index]\n",
        "        y_cv_val = y_train[val_index]\n",
        "\n",
        "        # Entrenar el modelo KShape con la configuración actual\n",
        "        model = KShape(n_clusters=params['n_clusters'],\n",
        "                       n_init=params['n_init'],\n",
        "                       tol=params['tol'],\n",
        "                       random_state=0)\n",
        "        model.fit(X_cv_train)\n",
        "\n",
        "        # Predecir en el fold de validación\n",
        "        y_pred_val = model.predict(X_cv_val)\n",
        "        mapped_val, _ = map_clusters_to_labels(y_pred_val, y_cv_val)\n",
        "        cv_acc = accuracy_score(y_cv_val, mapped_val)\n",
        "        cv_scores.append(cv_acc)\n",
        "\n",
        "    mean_cv_score = np.mean(cv_scores)\n",
        "    print(f\"Configuración: {params} -> CV Accuracy: {mean_cv_score:.4f}\")\n",
        "    if mean_cv_score > best_cv_score:\n",
        "        best_cv_score = mean_cv_score\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\n====== Mejor configuración (CV) ======\")\n",
        "print(\"Mejor configuración:\", best_params)\n",
        "print(\"Mejor CV Accuracy:\", best_cv_score)\n",
        "\n",
        "# Reentrenar el modelo con la mejor configuración en todo el conjunto de entrenamiento\n",
        "best_model = KShape(n_clusters=best_params['n_clusters'],\n",
        "                    n_init=best_params['n_init'],\n",
        "                    tol=best_params['tol'],\n",
        "                    random_state=0)\n",
        "best_model.fit(X_train_scaled)\n",
        "\n",
        "# Evaluar en el conjunto de entrenamiento\n",
        "y_pred_train = best_model.predict(X_train_scaled)\n",
        "mapped_train, _ = map_clusters_to_labels(y_pred_train, y_train)\n",
        "train_acc = accuracy_score(y_train, mapped_train)\n",
        "print(\"\\n====== Evaluación en el conjunto de entrenamiento ======\")\n",
        "print(\"Train Accuracy:\", train_acc)\n",
        "print(\"\\nReporte de clasificación (Entrenamiento):\")\n",
        "print(classification_report(y_train, mapped_train))\n",
        "cm_train = confusion_matrix(y_train, mapped_train)\n",
        "print(\"\\nMatriz de confusión (Entrenamiento):\")\n",
        "print(cm_train)\n",
        "\n",
        "# Evaluar en el conjunto de prueba\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "mapped_test, _ = map_clusters_to_labels(y_pred_test, y_test)\n",
        "test_acc = accuracy_score(y_test, mapped_test)\n",
        "print(\"\\n====== Evaluación en el conjunto de prueba ======\")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"\\nReporte de clasificación (Prueba):\")\n",
        "print(classification_report(y_test, mapped_test))\n",
        "cm_test = confusion_matrix(y_test, mapped_test)\n",
        "print(\"\\nMatriz de confusión (Prueba):\")\n",
        "print(cm_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eRwGd12TI90",
        "outputId": "681c4dfc-b5ae-4a39-e506-1467af26bfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando validación cruzada sobre el grid de parámetros...\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 0.0001}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 0.0001} -> CV Accuracy: 0.8075\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-05}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-05} -> CV Accuracy: 0.8125\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-06}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-06} -> CV Accuracy: 0.8125\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-07}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-07} -> CV Accuracy: 0.8125\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-08}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 1, 'tol': 1e-08} -> CV Accuracy: 0.8125\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 0.0001}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 0.0001} -> CV Accuracy: 0.8175\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-05}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-05} -> CV Accuracy: 0.8175\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-06}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-06} -> CV Accuracy: 0.8175\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-07}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-07} -> CV Accuracy: 0.8175\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-08}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 1e-08} -> CV Accuracy: 0.8175\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 0.0001}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 0.0001} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-05}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-05} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-06}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-06} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-07}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-07} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-08}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 5, 'tol': 1e-08} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 0.0001}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 0.0001} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-05}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-05} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-06}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-06} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-07}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-07} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-08}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 7, 'tol': 1e-08} -> CV Accuracy: 0.7850\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 0.0001}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 0.0001} -> CV Accuracy: 0.7925\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-05}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-05} -> CV Accuracy: 0.7925\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-06}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-06} -> CV Accuracy: 0.7925\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-07}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-07} -> CV Accuracy: 0.7925\n",
            "\n",
            "Probando configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-08}\n",
            "Configuración: {'n_clusters': 2, 'n_init': 10, 'tol': 1e-08} -> CV Accuracy: 0.7925\n",
            "\n",
            "====== Mejor configuración (CV) ======\n",
            "Mejor configuración: {'n_clusters': 2, 'n_init': 3, 'tol': 0.0001}\n",
            "Mejor CV Accuracy: 0.8174999999999999\n",
            "\n",
            "====== Evaluación en el conjunto de entrenamiento ======\n",
            "Train Accuracy: 0.895\n",
            "\n",
            "Reporte de clasificación (Entrenamiento):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.97      0.93       310\n",
            "         1.0       0.88      0.62      0.73        90\n",
            "\n",
            "    accuracy                           0.90       400\n",
            "   macro avg       0.89      0.80      0.83       400\n",
            "weighted avg       0.89      0.90      0.89       400\n",
            "\n",
            "\n",
            "Matriz de confusión (Entrenamiento):\n",
            "[[302   8]\n",
            " [ 34  56]]\n",
            "\n",
            "====== Evaluación en el conjunto de prueba ======\n",
            "Test Accuracy: 0.98\n",
            "\n",
            "Reporte de clasificación (Prueba):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99        90\n",
            "         1.0       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.98       100\n",
            "   macro avg       0.94      0.94      0.94       100\n",
            "weighted avg       0.98      0.98      0.98       100\n",
            "\n",
            "\n",
            "Matriz de confusión (Prueba):\n",
            "[[89  1]\n",
            " [ 1  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tslearn.clustering import KShape\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
        "from tslearn.utils import to_time_series_dataset\n",
        "from sklearn.model_selection import train_test_split, KFold, ParameterGrid\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, adjusted_rand_score\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.stats import mode\n",
        "\n",
        "# ===================== CARGA Y PREPROCESAMIENTO =====================\n",
        "# Cargar datos\n",
        "data = np.loadtxt(\"/mnt/DGX0Raid/databases/bonn_dataset_columns_correct.csv\", delimiter=\",\").T\n",
        "X_raw = data[:, 1:]\n",
        "y = data[:, 0].astype(int)\n",
        "\n",
        "# Convertir a dataset de series temporales\n",
        "X = to_time_series_dataset(X_raw)\n",
        "\n",
        "# Dividir en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extraer primeros 21 segundos\n",
        "def extract_21_seconds_generator(X, fs=173.61, window_duration=21):\n",
        "    num_samples = int(window_duration * fs)\n",
        "    for signal in X:\n",
        "        yield signal[:num_samples]\n",
        "\n",
        "X_train_extracted = np.array(list(extract_21_seconds_generator(X_train))).squeeze(-1)\n",
        "X_test_extracted = np.array(list(extract_21_seconds_generator(X_test))).squeeze(-1)\n",
        "\n",
        "# Filtro pasa bajos\n",
        "def low_pass_filter(signal, cutoff=40.0, fs=173.61, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "X_train_filtered = np.array([low_pass_filter(sig) for sig in X_train_extracted])\n",
        "X_test_filtered = np.array([low_pass_filter(sig) for sig in X_test_extracted])\n",
        "\n",
        "# Escalado\n",
        "scaler = TimeSeriesScalerMeanVariance(mu=0., std=1.)\n",
        "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
        "X_test_scaled = scaler.transform(X_test_filtered)\n",
        "\n",
        "# ===================== FUNCIÓN DE MAPEADO =====================\n",
        "def map_clusters_to_labels(clusters, true_labels):\n",
        "    true_labels = np.array(true_labels, dtype=int)\n",
        "    label_map = {}\n",
        "    for cluster in np.unique(clusters):\n",
        "        mask = (clusters == cluster)\n",
        "        true_mode = mode(true_labels[mask], keepdims=True).mode[0]\n",
        "        label_map[cluster] = true_mode\n",
        "    return np.array([label_map[c] for c in clusters]), label_map\n",
        "\n",
        "# ===================== VALIDACIÓN CRUZADA =====================\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "param_grid = {'n_clusters': [2], 'n_init': [3, 5, 6, 7, 10], 'tol': [1e-3, 1e-5, 1e-6, 1e-7, 1e-8]}\n",
        "\n",
        "fold_results = []\n",
        "best_cv_score = -np.inf\n",
        "\n",
        "print(\"Validación cruzada...\\n\")\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Probando configuración: {params}\")\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_scaled), 1):\n",
        "        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
        "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "        model = KShape(**params, random_state=0)\n",
        "        model.fit(X_tr)\n",
        "\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        mapped_val, _ = map_clusters_to_labels(y_val_pred, y_val)\n",
        "\n",
        "        metrics = {\n",
        "            'fold': fold,\n",
        "            'accuracy': accuracy_score(y_val, mapped_val),\n",
        "            'precision': precision_score(y_val, mapped_val, average='macro'),\n",
        "            'recall': recall_score(y_val, mapped_val, average='macro'),\n",
        "            'f1': f1_score(y_val, mapped_val, average='macro'),\n",
        "            'ari': adjusted_rand_score(y_val, y_val_pred)\n",
        "        }\n",
        "        fold_results.append(metrics)\n",
        "        print(f\"Fold {fold} - Acc: {metrics['accuracy']:.3f}, F1: {metrics['f1']:.3f}, ARI: {metrics['ari']:.3f}\")\n",
        "\n",
        "# Tabla de resultados\n",
        "results_df = pd.DataFrame(fold_results)\n",
        "print(\"\\nResumen de validación cruzada:\")\n",
        "print(results_df.describe().loc[['mean', 'std']])\n",
        "\n",
        "# ===================== MODELO FINAL =====================\n",
        "best_params = param_grid['n_clusters'][0], param_grid['n_init'][0], param_grid['tol'][0]\n",
        "model = KShape(n_clusters=2, n_init=5, tol=1e-6, random_state=0)\n",
        "model.fit(X_train_scaled)\n",
        "\n",
        "# ===================== EVALUACIÓN FINAL =====================\n",
        "def evaluate_and_print(X_set, y_true, model, set_name=\"\"):\n",
        "    y_pred = model.predict(X_set)\n",
        "    mapped_pred, _ = map_clusters_to_labels(y_pred, y_true)\n",
        "\n",
        "    acc = accuracy_score(y_true, mapped_pred)\n",
        "    prec = precision_score(y_true, mapped_pred, average='macro')\n",
        "    rec = recall_score(y_true, mapped_pred, average='macro')\n",
        "    f1 = f1_score(y_true, mapped_pred, average='macro')\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\n====== Evaluación en {set_name} ======\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(f\"ARI:       {ari:.4f}\")\n",
        "    print(\"\\nMatriz de confusión:\")\n",
        "    print(confusion_matrix(y_true, mapped_pred))\n",
        "\n",
        "    return acc, prec, rec, f1, ari, mapped_pred\n",
        "\n",
        "train_metrics = evaluate_and_print(X_train_scaled, y_train, model, \"train\")\n",
        "test_metrics = evaluate_and_print(X_test_scaled, y_test, model, \"test\")\n",
        "\n",
        "# ===================== VISUALIZACIÓN =====================\n",
        "# Señales promedio por cluster\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, center in enumerate(model.cluster_centers_):\n",
        "    plt.plot(center.ravel(), label=f'Centro cluster {i}')\n",
        "plt.title(\"Centros de los clusters (KShape)\")\n",
        "plt.xlabel(\"Tiempos\")\n",
        "plt.ylabel(\"Amplitud\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Señales individuales por cluster (hasta 5 señales por cluster)\n",
        "assignments = model.predict(X_train_scaled)\n",
        "for cluster_id in np.unique(assignments):\n",
        "    signals = X_train_scaled[assignments == cluster_id]\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(min(5, len(signals))):\n",
        "        plt.plot(signals[i].ravel(), alpha=0.6, label=f'Señal {i+1}')\n",
        "    plt.title(f\"Señales en cluster {cluster_id}\")\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "oC02CeVcRPtR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}